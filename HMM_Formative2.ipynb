{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Model for Human Activity Recognition",
    "This notebook implements data preprocessing, feature extraction, model training, and evaluation using Hidden Markov Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.fft import fft\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from hmmlearn import hmm\n",
    "import glob, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from /data folder\n",
    "data_files = glob.glob('data/*.csv')\n",
    "dfs = []\n",
    "for file in data_files:\n",
    "    df = pd.read_csv(file)\n",
    "    df['activity'] = os.path.basename(file).split('_')[0].lower()\n",
    "    dfs.append(df)\n",
    "raw_data = pd.concat(dfs, ignore_index=True)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction function\n",
    "def extract_features(df):\n",
    "    feats = {}\n",
    "    for axis in ['x', 'y', 'z']:\n",
    "        feats[f'mean_{axis}'] = df[axis].mean()\n",
    "        feats[f'std_{axis}'] = df[axis].std()\n",
    "    sma = np.mean(np.abs(df[['x','y','z']])).sum()\n",
    "    feats['sma'] = sma\n",
    "    freq = np.abs(fft(df['x']))\n",
    "    feats['dominant_freq'] = np.argmax(freq)\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature dataset\n",
    "feature_rows = []\n",
    "for file in data_files:\n",
    "    df = pd.read_csv(file)\n",
    "    feats = extract_features(df)\n",
    "    feats['activity'] = os.path.basename(file).split('_')[0].lower()\n",
    "    feature_rows.append(feats)\n",
    "features_df = pd.DataFrame(feature_rows)\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and encode\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(features_df.drop('activity', axis=1))\n",
    "y = features_df['activity'].astype('category').cat.codes\n",
    "activity_map = dict(enumerate(features_df['activity'].astype('category').cat.categories))\n",
    "X[:5], y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train HMM\n",
    "model = hmm.GaussianHMM(n_components=len(activity_map), covariance_type='diag', n_iter=100)\n",
    "model.fit(X)\n",
    "predicted_states = model.predict(X)\n",
    "decoded_labels = [activity_map[s] for s in predicted_states]\n",
    "pd.DataFrame({'True': features_df['activity'], 'Predicted': decoded_labels}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance\n",
    "cm = confusion_matrix(features_df['activity'], decoded_labels, labels=activity_map.values())\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=activity_map.values(), yticklabels=activity_map.values())\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "acc = accuracy_score(features_df['activity'], decoded_labels)\n",
    "print(f'Overall Accuracy: {acc:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}